{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing OLS and Double Selection\n",
    "This material is originally developed for ACE 592 Big Data - Empirical Economics written on 7/21/2017 by Alex Stevens. \n",
    "\n",
    "### Motivation\n",
    "Researchers do not know the data generating process for the data they are analyzing. This exercise creates a nonlinear data generating process that is too complex for simple modelling to capture, then compares OLS and Double Selection estimation.\n",
    "\n",
    "### Objective:\n",
    "* Create Monte Carlo experiement\n",
    "* Compare distribution of coeffiecients estimated by OLS and Double Selection \n",
    "* Look at the effects of assumptions on these two models\n",
    "\n",
    "Remember to shut down your server when you are done by clicking Control Panel -> Shut Down Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rm(list=ls())\n",
    "## This function will check if a package is installed, and if not, install it\n",
    "pkgTest <- function(x) {\n",
    "  if (!require(x, character.only = TRUE))\n",
    "  {\n",
    "    install.packages(x, dep = TRUE, repos = \"http://cran.us.r-project.org\")\n",
    "    if(!require(x, character.only = TRUE)) stop(\"Package not found\")\n",
    "  }\n",
    "}\n",
    "\n",
    "## These lines load the required packages\n",
    "packages <- c(\"Hmisc\", \"hdm\",\"mvtnorm\")\n",
    "lapply(packages, pkgTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set seed for replication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N <- 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set number of simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n.sims <- 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create matrix of 200 random normally distributed variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x <- matrix(runif(N*50), nrow = N, ncol = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create polynomials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polyx<-cbind(x^2,x^3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 5 bins for first 40 variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvar<-10\n",
    "quants<-5\n",
    "dumx<-matrix(nrow=N,ncol=quants*nvar)\n",
    "  for(i in 1:nvar){\n",
    "    indx<- factor(as.numeric(cut2(x[,i], g=quants)))\n",
    "    dumx[,((quants*i)-(quants-1)):(quants*i)]<-model.matrix(~indx-1)\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create treatment variable where half of the observations are treatment half are control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " Treatment<-sample(rep(0:1,N/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create true y. Note:\n",
    "* True effect of Treatment on y is 1\n",
    "* Most x variables have no effect on y\n",
    "* Some x variables have nonlinear effects on y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  y <- Treatment+x[,1] * 2+ x[,2] * 2.5 + 600*x[,3]-20*x[,3]^2-20*x[,3]^3+\n",
    "                #3*exp(x[,4]+x[,10])+2*log(x[,6]+x[,10]+100)+ \n",
    "                600*x[,7]^2+30*x[,8]^2- 20*x[,8]^3+\n",
    "                300*dumx[,(quants*5)]+90*dumx[,(quants*5)+1]+30*dumx[,(quants*5)+2]+\n",
    "                100*dumx[,(quants*8)+1]+50*dumx[,(quants*8)+2]+70*dumx[,(quants*8)+3]+\n",
    "                10*dumx[,(quants*9)]+60*dumx[,(quants*9)+3]-6*dumx[,(quants*9)+5]+\n",
    "                rnorm(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Analyze Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate naive OLS model using only x variables and summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.lm <- lm(y~Treatment+x)\n",
    "summary(fit.lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate naive Double Selection model using only x variables and summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.ds <- rlassoEffect(x, y, Treatment, method = \"double selection\")\n",
    "summary(fit.ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now assume some x variables have polynomial effects on y and estimate OLS with x and polyx variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.lm.os <- lm(y~Treatment+x+polyx)\n",
    "  summary(fit.lm.os)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume some x variables have binned effects on y and estimate OLS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.lm.os <- lm(y~Treatment+x+dumx+polyx)\n",
    "  summary(fit.lm.os)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume some x variables have binned and polynomial effects on y and estimate double selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xds<-cbind(x,dumx,polyx)\n",
    "  \n",
    "fit.ds.os <- rlassoEffect(xds, y, Treatment, method = \"double selection\")\n",
    "summary(fit.ds.os)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Monte Carlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of these method give much different coefficients for Treatment. We will use a Monte Carlo to visualize the distribution of coefficients and measure the type 1 and type 2 errors for the tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create output matrices\n",
    "Prefixes:\n",
    "* betahat~ -- estimates of Treatment coefficient\n",
    "* type1~ -- type one error(1), no type one error(0)\n",
    "* type2~ -- type two error(1), no type two error(0), where false null is less than or equal to zero \n",
    "\n",
    "Suffixes:\n",
    "* ~ols -- OLS estimation naive model\n",
    "* ~ols.os -- OLS estimation overspecified model\n",
    "* ~ds -- DS estimation naive model\n",
    "* ~ds.os -- DS estimation overspecified model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betahat.ols <- matrix(NA,nrow=n.sims,ncol=3)\n",
    "betahat.ds <- matrix(NA,nrow=n.sims,ncol=1)\n",
    "betahat.ols.os <- matrix(NA,nrow=n.sims,ncol=3)\n",
    "betahat.ds.os <- matrix(NA,nrow=n.sims,ncol=1)\n",
    "type1.ols <- matrix(NA,nrow=n.sims,ncol=1)\n",
    "type1.ds <- matrix(NA,nrow=n.sims,ncol=1)\n",
    "type1.ols.os <- matrix(NA,nrow=n.sims,ncol=1)\n",
    "type1.ds.os <- matrix(NA,nrow=n.sims,ncol=1)\n",
    "type2.ols <- matrix(NA,nrow=n.sims,ncol=1)\n",
    "type2.ds <- matrix(NA,nrow=n.sims,ncol=1)\n",
    "type2.ols.os <- matrix(NA,nrow=n.sims,ncol=1)\n",
    "type2.ds.os <- matrix(NA,nrow=n.sims,ncol=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Takes 15-20 minutes to run\n",
    "* Run the Monte Carlo experiment using previously described data generating process\n",
    "\n",
    "* Calculate type 1 and type 2 errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for(j in 1:n.sims){\n",
    "# Create data  \n",
    "  x <- matrix(runif(N*50), nrow = N, ncol = 50)\n",
    "  Treatment<-sample(rep(0:1,N/2))\n",
    "  polyx<-cbind(x^2,x^3)\n",
    "  nvar<-20\n",
    "    quants<-5\n",
    "    dumx<-matrix(nrow=N,ncol=5*nvar)\n",
    "  for(i in 1:nvar){\n",
    "    indx<- factor(as.numeric(cut2(x[,i], g=quants)))\n",
    "    dumx[,((quants*i)-(quants-1)):(quants*i)]<-model.matrix(~indx-1)\n",
    "  }\n",
    "# Create y    \n",
    "  y <- Treatment+x[,1] * 2+ x[,2] * 2.5 + 600*x[,3]-20*x[,3]^2-20*x[,3]^3+\n",
    "                #3*exp(x[,4]+x[,10])+2*log(x[,6]+x[,10]+100)+ \n",
    "                600*x[,7]^2+30*x[,8]^2- 20*x[,8]^3+\n",
    "                300*dumx[,(quants*5)]+90*dumx[,(quants*5)+1]+30*dumx[,(quants*5)+2]+\n",
    "                100*dumx[,(quants*8)+1]+50*dumx[,(quants*8)+2]+70*dumx[,(quants*8)+3]+\n",
    "                10*dumx[,(quants*9)]+60*dumx[,(quants*9)+3]-6*dumx[,(quants*9)+5]+\n",
    "                rnorm(N)\n",
    "#### Estimating true relationships\n",
    "# Estimate naive OLS  \n",
    "  fit.lm <- lm(y~Treatment+x)\n",
    "  summary(fit.lm)\n",
    "  \n",
    "  b<-coef(summary(fit.lm))[,\"Estimate\"][2]\n",
    "  s<-coef(summary(fit.lm))[,\"Std. Error\"][2]\n",
    "  p<-coef(summary(fit.lm))[,\"Pr(>|t|)\"][2]\n",
    "   \n",
    "  t<-(b-1)/(s/sqrt(N))\n",
    "# Store relavant statistics\n",
    "  betahat.ols[j,]<-b\n",
    "  \n",
    "  if(t>1.96){\n",
    "    type1.ols[j,1]<-1\n",
    "  }\n",
    "  else{\n",
    "    type1.ols[j,1]<-0\n",
    "  }\n",
    "  \n",
    "  if(b<0 | p>.05){\n",
    "    type2.ols[j,1]<-1\n",
    "  }\n",
    "  else{\n",
    "    type2.ols[j,1]<-0\n",
    "  }\n",
    "\n",
    "# Estimate naive DS  \n",
    "  fit.ds <- rlassoEffect(x, y, Treatment, method = \"double selection\")\n",
    "  summary(fit.ds)\n",
    "  \n",
    "  b.ds<-coef(summary(fit.ds))[,\"Estimate.\"][1]\n",
    "  s.ds<-coef(summary(fit.ds))[,\"Std. Error\"][1]\n",
    "  p.ds<-coef(summary(fit.ds))[,\"Pr(>|t|)\"][1]\n",
    "  \n",
    "  t.ds<-(b.ds-1)/(s.ds/sqrt(N))\n",
    "# Store relavant statistics  \n",
    "  betahat.ds[j,]<-b.ds\n",
    "  \n",
    "  if(t.ds>1.96){\n",
    "    type1.ds[j,1]<-1\n",
    "  }\n",
    "  else{\n",
    "    type1.ds[j,1]<-0\n",
    "  }\n",
    "  if(b.ds<0 | p.ds>.05){\n",
    "    type2.ds[j,1]<-1\n",
    "  }\n",
    "  else{\n",
    "    type2.ds[j,1]<-0\n",
    "  }\n",
    " \n",
    "## Overspecify\n",
    "# Estimate overspecified OLS \n",
    "  fit.lm.os <- lm(y~Treatment+x+dumx)\n",
    "  summary(fit.lm.os)\n",
    "  \n",
    "  \n",
    "  b.os<-coef(summary(fit.lm.os))[,\"Estimate\"][2]\n",
    "  s.os<-coef(summary(fit.lm.os))[,\"Std. Error\"][2]\n",
    "  p.os<-coef(summary(fit.lm.os))[,\"Pr(>|t|)\"][2]\n",
    "  \n",
    "  t.os<-(b.os-1)/(s.os/sqrt(N))\n",
    "# Store relavant statistics  \n",
    "  betahat.ols.os[j,]<-b.os\n",
    "  \n",
    "  if(t.os>1.96){\n",
    "    type1.ols.os[j,1]<-1\n",
    "  }\n",
    "  else{\n",
    "    type1.ols.os[j,1]<-0\n",
    "  }\n",
    "  \n",
    "  if(b.os<0 | p.os>.05){\n",
    "    type2.ols.os[j,1]<-1\n",
    "  }\n",
    "  else{\n",
    "    type2.ols.os[j,1]<-0\n",
    "  }\n",
    "\n",
    "# Estimate overspecified DS\n",
    "  xds<-cbind(x,dumx,polyx)\n",
    "  \n",
    "  fit.ds.os <- rlassoEffect(xds, y, Treatment, method = \"double selection\")\n",
    "  summary(fit.ds.os)\n",
    "  \n",
    "  b.ds.os<-coef(summary(fit.ds.os))[,\"Estimate.\"][1]\n",
    "  s.ds.os<-coef(summary(fit.ds.os))[,\"Std. Error\"][1]\n",
    "  p.ds.os<-coef(summary(fit.ds.os))[,\"Pr(>|t|)\"][1]\n",
    "  \n",
    "  t.ds.os<-(b.ds.os-1)/(s.ds.os/sqrt(N))\n",
    "# Store relavant statistics  \n",
    "  betahat.ds.os[j,]<-b.ds.os\n",
    "  \n",
    "  if(t.ds.os>1.96){\n",
    "    type1.ds.os[j,1]<-1\n",
    "  }\n",
    "  else{\n",
    "    type1.ds.os[j,1]<-0\n",
    "  }\n",
    "  \n",
    "  if(b.ds.os<0 | p.ds.os>.05){\n",
    "    type2.ds.os[j,1]<-1\n",
    "  }\n",
    "  else{\n",
    "    type2.ds.os[j,1]<-0\n",
    "  }\n",
    "  print(paste0(j, ' of ',n.sims))\n",
    "}\n",
    "\n",
    "# Print type 1 and type 2 errors\n",
    "print(paste0('type 1 error naive OLS rate = ',colMeans(type1.ols)))\n",
    "print(paste0('type 1 error naive DS rate = ',colMeans(type1.ds)))\n",
    "print(paste0('type 1 error overspecified OLS rate = ',colMeans(type1.ols.os)))\n",
    "print(paste0('type 1 error overspecified DS rate = ',colMeans(type1.ds.os)))\n",
    "\n",
    "print(paste0('type 2 error naive OLS rate = ',colMeans(type2.ols)))\n",
    "print(paste0('type 2 error naive DS rate = ',colMeans(type2.ds)))\n",
    "print(paste0('type 2 error overspecified OLS rate = ',colMeans(type2.ols.os)))\n",
    "print(paste0('type 2 error overspecified DS rate = ',colMeans(type2.ds.os)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Save density plots of coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "png(filename=paste(file.path(path.expand('~'),'outputs/Lab6/'),'MisspecDS.png'))\n",
    "\n",
    "plot (density(betahat.ds),col=\"red\",main = \"\",xlab=\"Treatment Coefficient Estimate (True = 1)\")\n",
    "title(main = \"Density Plot of naive Double Selection\")\n",
    "\n",
    "dev.off()\n",
    "\n",
    "png(filename=paste(file.path(path.expand('~'),'outputs/Lab6/'),'MisspecOLS.png'))\n",
    "\n",
    "plot (density(betahat.ols),col=\"red\",main = \"\",xlab=\"Treatment Coefficient Estimate (True = 1)\")\n",
    "title(main = \"Density Plot of naive OLS\")\n",
    "\n",
    "dev.off()\n",
    "\n",
    "\n",
    "png(filename=paste(file.path(path.expand('~'),'outputs/Lab6/'),'MisspecDSos.png'))\n",
    "\n",
    "plot (density(betahat.ds.os),col=\"red\",main = \"\",xlab=\"Treatment Coefficient Estimate (True = 1)\")\n",
    "title(main = \"Density Plot of overspecified Double Selection\")\n",
    "\n",
    "dev.off()\n",
    "\n",
    "png(filename=paste(file.path(path.expand('~'),'outputs/Lab6/'),'MisspecOLSos.png'))\n",
    "\n",
    "plot (density(betahat.ols.os),col=\"red\",main = \"\",xlab=\"Treatment Coefficient Estimate (True = 1)\")\n",
    "title(main = \"Density Plot of overspecified OLS\")\n",
    "\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Question 1\n",
    "\n",
    "Which the four methods has the best distribution? Why? What assumptions of OLS and DS are violated in the naive models? \n",
    "\n",
    "### Question 2\n",
    "\n",
    "Why does the overspecified OLS have a lower type 1 error rate? \n",
    "\n",
    "### Question 3\n",
    "\n",
    "The type 2 error rate is calculated incorrectly. Describe how would you correct it? \n",
    "\n",
    "### Question 4\n",
    "\n",
    "Create a correlation between the Treatment and the independent variables. How does this change the OLS and DS coefficents? What other methods can be used to deal with this specification?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the model or data generating process so that an assumption of double selection is violated. How does this affect the ability of the model to draw valid inference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
